#transCNNRE
Code implementation of the tensorflow version of the article "Deep Understanding for Distantly-Supervised Relation Extraction Extraction Using Transformer" submitted to ijicai 2019.

#Required
python >= 3.5
Tensorflow >= 1.12.0

#Data
We use the same dataset(NYT10) as in [Lin et al.,2016]. And we provide it in origin_data/ directory.
Pre-Trained Word Vectors are learned from New York Times Annotated Corpus (LDC Data LDC2008T19), which should be obtained from [[data]](https://catalog.ldc.upenn.edu/LDC2008T19). And we provide it also in the origin_data/ directory.
origin_data：in this folder, there is an origin.zip compressed file containing the original data set and the embedding file
- entity_category_id.txt We use Stanford's entity naming annotator to mark the entities in sentences. The entity types are divided into 4 categories:O（other）、LOCATION、PERSON、ORGANIZATION。
- train_type.csv training file, format (fb_mid_e1, fb_mid_e2, e1_name, e2_name,e1_type,e2_type, relation, sentence).
- test_type.csv test file, same format as train.txt.
- vec_add.txt the pre-train word embedding file.
entity_type/cnndata：In this folder, there is a compressed file named cnndata.zip, which contains some intermediate files could be generated by initial_entityType.py. Create new folders named "model" and "result" under /entity_type to store intermediate files.

#Codes
1. First, run the initialization file:
  python initial_entityType.py
  Running this command will initialize the original data, and the initialized data will be placed in "entity_type/cnndata" and "entity_type/data".
2. Training model:
  python cnnmodel_union_transformer_with_cnn_entity_desc_twoLoss.py
  Running this command will train the model (you can change the training parameters in this file), and the trained model will be saved in "entity_type/model".
3. Test:
  python test_entitytype.py
  Running this command will call the model file saved in entity_type/model for testing and display the test results (P@100, P@200, P@300).
